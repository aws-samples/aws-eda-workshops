AWSTemplateFormatVersion: "2010-09-09"
Description: |
  This template deploys a login server, an LSF master server, a supporting NFS file system,
  and installs LSF software that you provide.

  **WARNING** This template creates Amazon EC2 instances, an FSx for NetApp ONTAP file system, and related resources.
  You will be billed for the AWS resources used if you create a stack from this template.

Mappings:
  RegionMap:
    ap-northeast-1:      # Tokyo
      Rocky8: ami-0025f1507e375f161
    ap-northeast-2:      # Seoul
      Rocky8: ami-05d54bac15231e6fa
    ap-southeast-1:      # Singapore
      Rocky8: ami-0506f2d559a79a962
    ap-southeast-2:      # Sydney
      Rocky8: ami-02b9a6992a20eed2b
    ca-central-1:        # Canada Central
      Rocky8: ami-0829e4c2a7a2dcce1
    eu-west-1:           # Dublin
      Rocky8: ami-0c14153c77f34b870
    us-east-1:           # N. Virginia
      Rocky8: ami-011ef2017d41cb239
    us-east-2:           # Ohio
      Rocky8: ami-02391db2758465a87
    us-west-2:           # Oregon
      Rocky8: ami-0f74cc83310468775

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      -
        Label:
          default: "Network configuration"
        Parameters:
          - VpcId
          - LoginServerSubnet
          - ComputeNodeSubnet
          - SshSource
          - AdminKeyPair
      -
        Label:
          default: "LSF software configuration"
        Parameters:
          - LSFInstallPath
          - LSFClusterName
          - CustomerLSFInstallUri
          - CustomerLSFBinsUri
          - CustomerLSFArmv8BinsUri
          - CustomerLSFEntitlementUri
          - CustomerLSFFixPackUri
          - CustomerLSFArmv8FixPackUri
          - ComputeAMI
      -
        Label:
          default: "LSF master configuration"
        Parameters:
          - MasterInstanceType
          - MasterServerAMI
      -
        Label:
          default: "Login Server Configuration"
        Parameters:
          - LoginServerInstanceType
          - UserName

    ParameterLabels:
      VpcId:
        default: Cluster VPC
      AdminKeyPair:
        default: EC2 Key Pair
      SshSource:
        default: Source IP
      MasterInstanceType:
        default: LSF master instance type
      MasterServerAMI:
        default: Master server AMI (OS image)
      ComputeAMI:
        default: Compute node AMI (OS image)
      LSFClusterName:
        default: LSF cluster name
      LSFInstallPath:
        default: LSF install path
      LoginServerSubnet:
        default: Login server subnet
      ComputeNodeSubnet:
        default: Compute node subnet
      LoginServerInstanceType:
        default: Login server instance type
      UserName:
        default: DCV login username
      CustomerLSFInstallUri:
        default: LSF install script location
      CustomerLSFBinsUri:
        default: LSF distribution package location
      CustomerLSFArmv8BinsUri:
        default: LSF distribution package location for Armv8
      CustomerLSFEntitlementUri:
        default: LSF entitlement file location
      CustomerLSFFixPackUri:
        default: LSF fix pack
      CustomerLSFArmv8FixPackUri:
        default: LSF fix pack for Armv8

Parameters:
  VpcId:
    Description: The VPC in which to install the cluster resources
    Type: 'AWS::EC2::VPC::Id'
  AdminKeyPair:
    Description: The name of an existing EC2 Key Pair for cluster SSH logins
    Type: "AWS::EC2::KeyPair::KeyName"
    AllowedPattern: ".+"
  SshSource:
    Description: >
      The CIDR range of the remote hosts that are permitted to log into the infrastructure instances.
      Use your public IP address (http://checkip.amazonaws.com) suffixed with /32.
    Type: String
    Default: 0.0.0.0/32
    AllowedPattern: (\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/32
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/32.
  LoginServerSubnet:
    Description: The subnet for the Login server. This subnet must have access to the internet.
    Type: AWS::EC2::Subnet::Id
  ComputeNodeSubnet:
    Description: The subnet for the LSF compute nodes
    Type: AWS::EC2::Subnet::Id
  MasterInstanceType:
    Description: The instance type of the master node of the cluster
    Type: "String"
    Default: "m6i.2xlarge"
    AllowedValues:
      - m6i.xlarge
      - m6i.2xlarge
      - m6a.xlarge
      - m6a.2xlarge
  MasterServerAMI:
    Description: The AMI (OS image) for the master server."
    Type: "String"
    Default: "Rocky8"
    AllowedValues:
      - Rocky8
  ComputeAMI:
    Description: >
      The AMI (OS image) for the compute nodes and login servers.
    Type: "String"
    Default: "Rocky8"
    AllowedValues:
      - Rocky8
  LoginServerInstanceType:
    Description: The instance type for the login server
    Type: "String"
    Default: "m6i.xlarge"
    AllowedValues:
      - t3.xlarge
      - m6i.xlarge
      - m7i.xlarge
      - m6a.xlarge
      - m7a.xlarge
  LSFClusterName:
    Description: The LSF cluster name
    Type: "String"
    Default: "mycluster"
  LSFInstallPath:
    Description: >
      The shared NFS path for installing LSF. This will be created on the included NFS file system
      and mounted on all nodes in the cluster.
    Type: "String"
    Default: "/fsxn/tools/ibm/lsf"
  CustomerLSFInstallUri:
    Description: >
      The S3 URI to the LSF installer script package.
      Select package object in the console and choose Copy Path and paste here.
    Type: "String"
    Default: "s3://<your_bucket>/lsf10.1_lsfinstall_linux_x86_64.tar.Z"
    AllowedPattern: ^s3\:\/\/.*\/lsf10.1_lsfinstall_linux_x86_64.tar.Z$
  CustomerLSFBinsUri:
    Description: >
      The S3 URI to the LSF distribution package. This must be a full distribution and not a patch or Fix Pack package.
      Select package object in the console and choose Copy Path and paste here.
    Type: "String"
    Default: "s3://<your_bucket>/lsf10.1_linux2.6-glibc2.3-x86_64.tar.Z"
    AllowedPattern: ^s3\:\/\/.*\/lsf10.1_linux2.6-glibc2.3-x86_64.tar.Z$
  CustomerLSFArmv8BinsUri:
    Description: >
      The S3 URI to the LSF distribution package for Armv8. This must be a full distribution and not a patch or Fix Pack package.
      Select package object in the console and choose Copy Path and paste here.
    Type: "String"
    Default: "s3://<your_bucket>/lsf10.1_lnx312-lib217-armv8.tar.Z"
    AllowedPattern: ^s3\:\/\/.*\/lsf10.1_lnx312-lib217-armv8.tar.Z$
  CustomerLSFFixPackUri:
    Description: >
      The S3 URI to the LSF Fix Pack package. This must the lastest Fix Pack package.
      Select package object in the console and choose Copy Path and paste here.
    Type: "String"
    Default: "s3://<your_bucket>/lsf10.1_linux2.6-glibc2.3-x86_64-601547.tar.Z"
    #AllowedPattern: ^s3\:\/\/.*\/lsf10.1_linux2.6-glibc2.3-x86_64-601547.tar.Z$
  CustomerLSFArmv8FixPackUri:
    Description: >
      The S3 URI to the LSF Fix Pack package for Armv8. This must the lastest Fix Pack package.
      Select package object in the console and choose Copy Path and paste here.
    Type: "String"
    Default: "s3://<your_bucket>/lsf10.1_lnx312-lib217-armv8-601547.tar.Z"
    #AllowedPattern: ^s3\:\/\/.*\/lsf10.1_lnx312-lib217-armv8-601547.tar.Z$
  CustomerLSFEntitlementUri:
    Description: >
      The S3 URI to the LSF 10.1 entitlement file, lsf_std_entitlement.dat or lsf_adv_entitlement.dat.
      Select package object in the S3 console and choose Copy Path and paste here.
    Type: String
    Default: s3://<your_bucket>/lsf_std_entitlement.dat
    AllowedPattern: ^s3\:\/\/.*
  UserName:
    Default: simuser
    Description: The username for DCV remote desktop login
    MinLength: '4'
    Type: String
    ConstraintDescription: Must be at least four letters in length

Resources:
  InstanceWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  InstanceWaitCondition:
    DependsOn: LoginServerInstance
    Properties:
      Handle: !Ref 'InstanceWaitHandle'
      Timeout: '3600'
    Type: AWS::CloudFormation::WaitCondition

  LSFMasterInstance:
    Type: "AWS::EC2::Instance"
    DependsOn: FSxOntapFS
    CreationPolicy:
      ResourceSignal:
        Count: 1
        Timeout: PT15M
    Properties:
      InstanceType: !Ref MasterInstanceType
      ImageId:
        Fn::FindInMap:
        - RegionMap
        - !Ref AWS::Region
        - !Ref MasterServerAMI
      SubnetId: !Ref ComputeNodeSubnet
      SecurityGroupIds:
        - !Ref LSFMasterSG
      KeyName: !Ref AdminKeyPair
      IamInstanceProfile: !Ref LSFMasterInstanceProfile
      Tags:
        -
          Key: "Name"
          Value: !Join [ '', [ 'LSF Mgmt Host - ',!Ref LSFClusterName ] ]
        -
          Key: "Cluster"
          Value: !Ref LSFClusterName
      UserData:
        Fn::Base64:
          Fn::Sub:
            - |
              #!/bin/bash

              set -x
              exec > >(tee /var/log/user-data.log|logger -t user-data ) 2>&1

              echo "*** BEGIN LSF MASTER BOOTSTRAP ***"

              export LSF_INSTALL_DIR="${LSFInstallPath}/${LSFClusterName}"
              export LSF_INSTALL_DIR_ROOT="/`echo $LSF_INSTALL_DIR | cut -d / -f2`"
              export FSXN_SVM_DNS_NAME="${FSxOntapStorageVirtualMachine}.${FSxOntapFS}.fsx.${AWS::Region}.amazonaws.com"
              export LSF_ADMIN=lsfadmin
              export LSF_INSTALL_PKG=`echo ${CustomerLSFInstallUri} | awk -F "/" '{print $NF}'`
              export LSF_BIN_PKG=`echo ${CustomerLSFBinsUri} | awk -F "/" '{print $NF}'`
              export LSF_ARMV8_BIN_PKG=`echo ${CustomerLSFArmv8BinsUri} | awk -F "/" '{print $NF}'`
              export LSF_FP_PKG=`echo ${CustomerLSFFixPackUri} | awk -F "/" '{print $NF}'`
              export LSF_ARMV8_FP_PKG=`echo ${CustomerLSFArmv8FixPackUri} | awk -F "/" '{print $NF}'`
              export LSF_ENTITLEMENT=`echo ${CustomerLSFEntitlementUri} | awk -F "/" '{print $NF}'`

              # Install SSM so we can use SSM Session Manager and avoid ssh logins
              yum install -q -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
              systemctl enable amazon-ssm-agent
              systemctl start amazon-ssm-agent

              # Install and configure Amazon CloudWatch Agent
              echo "Install and configure Amazon CloudWatch Agent"
              machine=$(uname -m)
              if [[ $machine == "x86_64" ]]; then
                yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/redhat/amd64/latest/amazon-cloudwatch-agent.rpm
              elif [[ $machine == "aarch64" ]]; then
                yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/redhat/arm64/latest/amazon-cloudwatch-agent.rpm
              fi

              # Disable Hyperthreading
              echo "Disabling Hyperthreading"
              for cpunum in $(awk -F'[,-]' '{print $2}' /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | sort -un);
              do
                echo 0 > /sys/devices/system/cpu/cpu$cpunum/online
              done

              OS_NAME=`awk -F= '/^NAME=/{print $2}' /etc/os-release`
              OS_VERSION=`awk -F= '/^VERSION_ID=/{print $2}' /etc/os-release`
              if [ "$OS_NAME" == "\"Rocky Linux\"" ] && [ "$OS_VERSION" == "\"8.9\"" ]; then
                OS="rocky8"
                yum clean all
                yum install -y python3 wget unzip libnsl vim bc
                pip3 install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-py3-2.0-29.tar.gz
                curl -s "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                unzip -q awscliv2.zip
                ./aws/install
              elif [ "$OS_NAME" == "\"Amazon Linux\"" ] && [ "$OS_VERSION" == "\"2\"" ]; then
                OS="amazonlinux2"
                # Install cfn-signal helper script to signal bootstrap completion to CloudFormation
                yum update -y aws-cfn-bootstrap
              fi

              # Install LSF installer prereqs
              yum install -y ed java-1.8.0-openjdk wget vim

              ## Mount NFS file system for LSF install
              # Create mount point
              mkdir -p $LSF_INSTALL_DIR_ROOT

              # Mount FSxN file system
              mount -t nfs -o "rsize=262144,wsize=262144,hard,vers=3,tcp,mountproto=tcp" $FSXN_SVM_DNS_NAME:/vol1 $LSF_INSTALL_DIR_ROOT

              #add to fstab
              echo "$FSXN_SVM_DNS_NAME:/vol1 $LSF_INSTALL_DIR_ROOT nfs nfsvers=3,rsize=262144,wsize=262144,tcp,hard 0 0" >> \
                /etc/fstab

              mkdir -p {$LSF_INSTALL_DIR,$LSF_INSTALL_DIR_ROOT/proj,$LSF_INSTALL_DIR_ROOT/scratch}
              chmod 777 $LSF_INSTALL_DIR_ROOT/{proj,scratch}
              mkdir -p /var/log/lsf && chmod 777 /var/log/lsf

              # TODO: Setup CloudWatch Logs daemon and send LSF logs to CloudWatch              # See docs

              ##############################################
              # Install LSF using customer-provided packages
              ##############################################

              # Add LSF admin account
              adduser -m -u 1500 $LSF_ADMIN

              # Download customer-provided LSF binaries and entitlement file
              aws --quiet s3 cp ${CustomerLSFInstallUri} /tmp
              aws --quiet s3 cp ${CustomerLSFBinsUri} /tmp
              aws --quiet s3 cp ${CustomerLSFArmv8BinsUri} /tmp
              aws --quiet s3 cp ${CustomerLSFEntitlementUri} /tmp
              aws --quiet s3 cp ${CustomerLSFFixPackUri} /tmp
              aws --quiet s3 cp ${CustomerLSFArmv8FixPackUri} /tmp

              cd /tmp
              tar xf $LSF_INSTALL_PKG
              cp $LSF_BIN_PKG lsf10.1_lsfinstall
              cd lsf10.1_lsfinstall

              # Create LSF installer config file
              HOSTNAME=$(hostname -s)
              cat << EOF > install.config
              LSF_TOP="$LSF_INSTALL_DIR"
              LSF_ADMINS="$LSF_ADMIN"
              LSF_CLUSTER_NAME="${LSFClusterName}"
              LSF_MASTER_LIST="${!HOSTNAME%%.*}"
              SILENT_INSTALL="Y"
              LSF_SILENT_INSTALL_TARLIST="ALL"
              ACCEPT_LICENSE="Y"
              LSF_ENTITLEMENT_FILE="/tmp/$LSF_ENTITLEMENT"
              EOF

              ./lsfinstall -f install.config

              # Setup LSF environment
              source $LSF_INSTALL_DIR/conf/profile.lsf

              # Install fix pack
              cd $LSF_INSTALL_DIR/10.1/install
              cp /tmp/$LSF_FP_PKG .
              cp /tmp/$LSF_ARMV8_FP_PKG .
              echo "schmod_demand.so" >> patchlib/daemonlists.tbl
              ./patchinstall --silent $LSF_FP_PKG
              ./patchinstall --silent $LSF_ARMV8_FP_PKG

              ## Create Resource Connector config dir
              mkdir -p $LSF_ENVDIR/resource_connector/aws/conf
              chown -R lsfadmin:root $LSF_ENVDIR/resource_connector/aws

              # Configure LSF and Resource Connector
              # Sets AWS as the sole host provider
              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/hostProviders.json \
                -O $LSF_ENVDIR/resource_connector/hostProviders.json

              # awsprov_config.json
              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/awsprov_config.json \
                -O $LSF_ENVDIR/resource_connector/aws/conf/awsprov_config.json
              sed -i -e "s/_CFN_AWS_REGION_/${AWS::Region}/" $LSF_ENVDIR/resource_connector/aws/conf/awsprov_config.json

              # awsprov_templates.json
              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/awsprov_templates.json \
                -O $LSF_ENVDIR/resource_connector/aws/conf/awsprov_templates.json

              sed -i -e "s|%CFN_COMPUTE_AMI%|${LSFComputeNodeAmi}|" \
                     -e "s|%CFN_COMPUTE_NODE_SUBNET%|${ComputeNodeSubnet}|" \
                     -e "s|%CFN_ADMIN_KEYPAIR%|${AdminKeyPair}|" \
                     -e "s|%CFN_COMPUTE_SECURITY_GROUP_ID%|${LSFComputeNodeSGGroupId}|" \
                     -e "s|%CFN_LSF_COMPUTE_NODE_INSTANCE_PROFILE_ARN%|${LSFComputeNodeInstanceProfileArn}|" \
                     -e "s|%CFN_LSF_CLUSTER_NAME%|${LSFClusterName}|" \
                     -e "s|%CFN_FSXN_SVM_DNS_NAME%|$FSXN_SVM_DNS_NAME|" \
                     -e "s|%CFN_LSF_INSTALL_DIR%|$LSF_INSTALL_DIR|" \
                     -e "s|%CFN_NFS_MOUNT_POINT%|$LSF_INSTALL_DIR_ROOT|" \
                     -e "s|%CFN_DCV_USER_NAME%|${UserName}|" \
                     -e "s|%CFN_LSF_COMPUTE_NODE_SPOT_FLEET_ROLE_ARN%|${LSFComputeNodeSpotFleetRoleArn}|" \
                  $LSF_ENVDIR/resource_connector/aws/conf/awsprov_templates.json

              # ec2-fleet-config.json
              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/ec2-fleet-config.json \
                 -O $LSF_ENVDIR/resource_connector/aws/conf/ec2-fleet-config.json

              sed -i -e "s|%CFN_COMPUTE_AMI%|${LSFComputeNodeAmi}|" \
                     -e "s|%CFN_COMPUTE_NODE_SUBNET%|${ComputeNodeSubnet}|" \
                     -e "s|%CFN_LAUNCH_TEMPLATE_ID%|${LaunchTemplate}|" $LSF_ENVDIR/resource_connector/aws/conf/ec2-fleet-config.json


              # user_data script that RC executes on compute nodes
              wget  https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/user_data.sh \
                -O $LSF_INSTALL_DIR/10.1/resource_connector/aws/scripts/user_data.sh
              chmod +x $LSF_INSTALL_DIR/10.1/resource_connector/aws/scripts/user_data.sh

              # Copy in pre-configured lsf config files
              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/lsf.shared \
                -O $LSF_ENVDIR/lsf.shared
              sed -i -e "s/^_CFN_LSF_CLUSTER_NAME_/${LSFClusterName}/" $LSF_ENVDIR/lsf.shared

              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/lsb.queues \
                -O $LSF_ENVDIR/lsbatch/${LSFClusterName}/configdir/lsb.queues

              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/lsb.modules \
                -O $LSF_ENVDIR/lsbatch/${LSFClusterName}/configdir/lsb.modules

              wget https://raw.githubusercontent.com/aws-samples/aws-eda-workshops/refs/heads/master/workshops/eda-workshop-lsf/config/lsf/lsb.params \
                -O $LSF_ENVDIR/lsbatch/${LSFClusterName}/configdir/lsb.params

              # lsf.cluster.*  Uncomment params to support dynamic hosts
              sed -i -e 's/#\sLSF_HOST_ADDR_RANGE/LSF_HOST_ADDR_RANGE/' \
                     -e 's/#\sFLOAT_CLIENTS/FLOAT_CLIENTS/' \
                  $LSF_ENVDIR/lsf.cluster.*


              # mosquitto.conf.  Enables mostquitto daemon, which RC uses to show bhosts -rc output.
              cat << EOF > $LSF_ENVDIR/mosquitto.conf
              log_dest file /var/log/lsf/mosquitto.log
              log_type all
              EOF
              chown $LSF_ADMIN $LSF_ENVDIR/mosquitto.conf

              # lsf.conf
              # Set logging to local file system
              sed -i -e 's|^LSF_LOGDIR.*|LSF_LOGDIR=/var/log/lsf|' $LSF_ENVDIR/lsf.conf

              # lsf.conf. Append RC config to config file that was created by LSF installer.
              cat << EOF >> $LSF_ENVDIR/lsf.conf

              LSF_STRIP_DOMAIN=.ec2.internal:.${AWS::Region}.compute.internal

              ######################################
              # LSF RESOURCE CONNECTOR CONFIGURATION
              ######################################

              LSB_RC_EXTERNAL_HOST_FLAG=aws

              # Adds 'aws' boolean to dynamic hosts
              LSF_LOCAL_RESOURCES="[resource aws] [type LINUX64]"

              #LSB_RC_MAX_INSTANCES_PER_TEMPLATE=1000

              #LSB_RC_DEFAULT_HOST_TYPE=X86_64

              LSB_RC_UPDATE_INTERVAL=10

              LSB_RC_QUERY_INTERVAL=15

              # Let LSB_RC_EXTERNAL_HOST_IDLE_TIME below shut down idle instances
              #LSB_RC_EXTERNAL_HOST_MAX_TTL=10

              LSB_RC_EXTERNAL_HOST_IDLE_TIME=10

              # starts the mosquitto daemon, which is required for the bhosts -rc and
              # bhosts -rconly commands to work.
              # mosquitto runs on default port 1883.
              LSF_MQ_BROKER_HOSTS=${!HOSTNAME}
              # The params below allow remote clients to query RC status from mosquitto
              MQTT_BROKER_HOST=${!HOSTNAME}
              MQTT_BROKER_PORT=1883

              #EBROKERD_HOST_CLEAN_DELAY=60

              ######################################
              # DYNAMIC HOST CONFIGURATION
              ######################################

              # Keep this less than 3 seconds for smooth RC operation.
              LSF_DYNAMIC_HOST_WAIT_TIME=3

              #LSF_REG_FLOAT_HOSTS=Y

              #LSF_DYNAMIC_HOST_KEEP=y

              #EGO_ENABLE_AUTO_DAEMON_SHUTDOWN=Y

              LSF_DYNAMIC_HOST_TIMEOUT=60m

              EOF


              # Configure system scripts to start LSF at boot time
              # Add cshrc.lsf and profile.lsf to system-wide environment
              # Start LSF daemons

              # FP14 implements a new systemd behavior.
              # Enable by copying new lsf_daemons into place or hostsetup will fail.
              # if fp14; then
              #   cp $LSF_INSTALL_DIR/10.1/install/instlib/startup.svr4 to <LSF_SERVERDIR>/lsf_daemons
              # OR just don't use --boot in hostsetup.

              patch_version=$(echo $LSF_FP_PKG | sed -E 's/.*-([0-9]+)\.tar\.Z/\1/')
              if [[ $patch_version -ge 601547 ]]; then
                cp $LSF_INSTALL_DIR/10.1/linux2.6-glibc2.3-x86_64/etc/lsf_daemons $LSF_INSTALL_DIR/10.1/linux2.6-glibc2.3-x86_64/etc/lsf_daemons.bak
                cp $LSF_INSTALL_DIR/10.1/install/instlib/startup.svr4 $LSF_INSTALL_DIR/10.1/linux2.6-glibc2.3-x86_64/etc/lsf_daemons
                sed -i "s,LSF_CONF=@LSF_CONF@,LSF_CONF=$LSF_ENVDIR/lsf.conf," $LSF_INSTALL_DIR/10.1/linux2.6-glibc2.3-x86_64/etc/lsf_daemons
                # Disable SELinux to enable the hostsetup services to start
                setenforce 0
                sed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
                $LSF_INSTALL_DIR/10.1/install/hostsetup --top="$LSF_INSTALL_DIR" \
                                                        --profile="y" \
                                                        --start="y" --boot="y"
              else
                $LSF_INSTALL_DIR/10.1/install/hostsetup --top="$LSF_INSTALL_DIR" \
                                                        --profile="y" \
                                                        --start="y" --boot="y"
              fi

              # Verify that LSF is up and send signal to Cloudformation
              sleep 10
              lsid
              if [ "$OS_NAME" == "\"Rocky Linux\"" ] && [ "$OS_VERSION" == "\"8.9\"" ]; then
                /usr/local/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource LSFMasterInstance --region ${AWS::Region}
              elif [ "$OS_NAME" == "\"Amazon Linux\"" ] && [ "$OS_VERSION" == "\"2\"" ]; then
                /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource LSFMasterInstance --region ${AWS::Region}
              fi

              echo "*** END LSF MASTER BOOTSTRAP ***"

            - LSFComputeNodeInstanceProfileArn: !GetAtt LSFComputeNodeInstanceProfile.Arn
              LSFComputeNodeSpotFleetRoleArn: !GetAtt LSFSpotFleetRole.Arn
              LSFComputeNodeSGGroupId: !Ref LSFComputeNodeSG
              LSFComputeNodeAmi: !FindInMap [ RegionMap, !Ref "AWS::Region", !Ref ComputeAMI ]

  LoginServerInstance:
    Type: "AWS::EC2::Instance"
    DependsOn: LSFMasterInstance
    Properties:
      InstanceType: !Ref LoginServerInstanceType
      ImageId:
        Fn::FindInMap:
        - RegionMap
        - !Ref AWS::Region
        - !Ref ComputeAMI
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeType: gp3
            VolumeSize: 12
            DeleteOnTermination: true
      SubnetId: !Ref LoginServerSubnet
      SecurityGroupIds:
        - !Ref LoginServerSG
      KeyName: !Ref AdminKeyPair
      IamInstanceProfile: !Ref LoginServerInstanceProfile
      Tags:
        -
          Key: "Name"
          Value: !Join [ '-', [ 'Login Server',!Ref LSFClusterName ] ]
        -
          Key: "Cluster"
          Value: !Ref LSFClusterName
      UserData:
        Fn::Base64:
          Fn::Sub: |
              #!/bin/bash

              set -x
              exec > >(tee /var/log/user-data.log|logger -t user-data ) 2>&1

              echo "*** BEGIN LOGIN SERVER BOOTSTRAP - `/bin/date` ***"
              my_wait_handle="${InstanceWaitHandle}"
              export LSF_INSTALL_DIR="${LSFInstallPath}/${LSFClusterName}"
              export LSF_INSTALL_DIR_ROOT="/`echo $LSF_INSTALL_DIR | cut -d / -f2`"
              export FSXN_SVM_DNS_NAME="${FSxOntapStorageVirtualMachine}.${FSxOntapFS}.fsx.${AWS::Region}.amazonaws.com"
              export LSF_ADMIN=lsfadmin

              OS_NAME=`awk -F= '/^NAME=/{print $2}' /etc/os-release`
              OS_VERSION=`awk -F= '/^VERSION_ID=/{print $2}' /etc/os-release`
              if [ "$OS_NAME" == "\"Rocky Linux\"" ] && [ "$OS_VERSION" == "\"8.9\"" ]; then
                OS="rocky8"
                yum install -y python3 wget unzip libnsl vim
                pip3 install https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-py3-2.0-29.tar.gz
                cd /tmp
                curl -s "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                unzip -q awscliv2.zip
                ./aws/install
              fi

              # Set DCV username and password
              export SM_PASSWORD=`/usr/local/bin/aws secretsmanager get-secret-value \
                                    --region ${AWS::Region} \
                                    --secret-id ${DCVCredentialsSecret} \
                                    --output text --query 'SecretString' \
                                   | python3 -c 'import json, sys; print(json.load(sys.stdin)["password"])'`

              user_name="${UserName}"
              user_pass=$SM_PASSWORD

              # Install SSM so we can use SSM Session Manager to avoid ssh logins.
              yum install -q -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
              systemctl enable amazon-ssm-agent
              systemctl start amazon-ssm-agent

              # Install packages needed for the lab
              dnf config-manager --enable powertools
              yum install -y make git autoconf gperf flex bison gcc-c++ gcc python3

              ## Mount NFS file system for LSF install
              #mount point
              mkdir -p $LSF_INSTALL_DIR_ROOT

               # Mount FSxN file system
              mount -t nfs -o rw,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 $FSXN_SVM_DNS_NAME:/vol1 $LSF_INSTALL_DIR_ROOT

              #add to fstab
              echo "$FSXN_SVM_DNS_NAME:/vol1 $LSF_INSTALL_DIR_ROOT nfs nfsvers=3,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2 0 0" >> \
                /etc/fstab

              # Set up LSF envrionment
              echo "source $LSF_INSTALL_DIR/conf/profile.lsf" > /etc/profile.d/lsf.sh

              # Install DCV
              echo "Installing DCV..."

              function install_prereqs {
                sudo yum clean all
                local MAX_ATTEMPTS=10
                local ATTEMPT_NUMBER=1
                local SLEEP_TIME_SECONDS=10
                while [ ${!ATTEMPT_NUMBER} -le ${!MAX_ATTEMPTS} ]; do
                   echo "Attempt ${!ATTEMPT_NUMBER} of ${!MAX_ATTEMPTS}"
                   df -h /
                   sudo yum -y groupinstall "Server with GUI" --allowerasing
                   if [ $? -eq 0 ]; then
                       echo "Command executed successfully after ${!ATTEMPT_NUMBER}/${!MAX_ATTEMPTS}!"
                       break
                   else
                       echo "Command failed. Retrying again in ${!SLEEP_TIME_SECONDS}..."
                       sleep ${!SLEEP_TIME_SECONDS}

                       ((ATTEMPT_NUMBER++))
                   fi
                done
                sudo yum -y install mesa-dri-drivers xterm gvim
                sed -i 's/#WaylandEnable=false/WaylandEnable=false/' /etc/gdm/custom.conf
                systemctl restart gdm
              }

              function install_dcv {
                mkdir -p /tmp/dcv-inst.d
                pushd /tmp/dcv-inst.d
                rpm --import https://d1uj6qtbmh3dt5.cloudfront.net/NICE-GPG-KEY
                wget https://d1uj6qtbmh3dt5.cloudfront.net/2024.0/Servers/nice-dcv-2024.0-19030-el8-x86_64.tgz
                tar -xvzf nice-dcv*.tgz
                cd $(find . -type d -name "nice-dcv*")
                yum -y install nice-dcv-server*.rpm \
                               nice-dcv-web-viewer*.rpm \
                               nice-xdcv*.rpm
                sed -i -e 's/#enable-quic-frontend=true/enable-quic-frontend=true/' /etc/dcv/dcv.conf
                popd
              }

              function add_user {

                user_name=${!user_name}
                user_pass=${!user_pass}

                groupadd -g 1501 ${!user_name}
                useradd ${!user_name} -u 1501 -m -g ${!user_name}
                echo "${!user_name}:${!user_pass}" | chpasswd
                echo "Created user ${!user_name}"

              }

              function cr_post_reboot {

                if [[ ! -d /opt/dcv-install ]]; then
                  mkdir -p /opt/dcv-install
                fi

              cat << EOF > /opt/dcv-install/post_reboot.sh
              #!/usr/bin/env bash

              function stop_disable_svc() {
                systemctl stop \$1
                systemctl disable \$1
              }

              stop_disable_svc firewalld
              stop_disable_svc libvirtd
              sudo systemctl set-default multi-user.target
              dcv create-session --type=virtual --owner ${!user_name} --user ${!user_name} --gl off simuser
              dcv list-sessions

              my_wait_handle="${!my_wait_handle}"

              if [[ ! -f /tmp/wait-handle-sent ]]; then
                exit 0
              else
                wait_handle_status=\$(cat /tmp/wait-handle-sent)
                if [[ \${!wait_handle_status} == "true" ]]; then
                  rm /tmp/wait-handle-sent
                  exit 0
                elif [[ \${!wait_handle_status} == "false" && \${!my_wait_handle} != "" ]] ; then
                  echo "Sending success to wait handle"
                  curl -X PUT -H 'Content-Type:' --data-binary '{ "Status" : "SUCCESS",  "Reason" : "instance launched",  "UniqueId" : "inst001",  "Data" : "instance launched."}' "\${!my_wait_handle}"
                  echo "true" > /tmp/wait-handle-sent
                fi
              fi

              EOF

              chmod 744 /opt/dcv-install/post_reboot.sh

              }

              function cr_service {

              cat << EOF > /etc/systemd/system/post-reboot.service
              [Unit]
              Description=Post reboot service

              [Service]
              ExecStart=/opt/dcv-install/post_reboot.sh

              [Install]
              WantedBy=multi-user.target
              EOF

              chmod 664 /etc/systemd/system/post-reboot.service
              systemctl daemon-reload
              systemctl enable post-reboot.service

              }

              function stop_disable_svc() {
                systemctl stop $1
                systemctl disable $1
              }


              function main {

              install_prereqs
              install_dcv
              add_user
              cr_post_reboot
              cr_service

              systemctl enable dcvserver
              echo "false" > /tmp/wait-handle-sent
              stop_disable_svc firewalld
              stop_disable_svc libvirtd
              echo "*** END LOGIN SERVER BOOTSTRAP - `/bin/date` ***"
              echo "Rebooting"
              reboot

              }

              main

  LoginServerRole:
      Type: "AWS::IAM::Role"
      Properties:
        Path: "/"
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            -
              Effect: Allow
              Principal:
                Service:
                - "ec2.amazonaws.com"
              Action:
              - "sts:AssumeRole"
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy"
          - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
          - "arn:aws:iam::aws:policy/SecretsManagerReadWrite"
        Policies:
          - PolicyName: DcvLicenseBucketPolicy
            PolicyDocument:
              Version: 2012-10-17
              Statement:
                - Effect: Allow
                  Action:
                    - s3:GetObject
                  Resource: arn:aws:s3:::dcv-license.us-east-1/*

  LoginServerInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: "/"
      Roles:
        - !Ref LoginServerRole

  LoginServerSG:
    Type: "AWS::EC2::SecurityGroup"
    Properties:
      GroupDescription: "SG for Login Servers"
      VpcId: !Ref VpcId
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: 22
        ToPort: 22
        CidrIp: !Ref SshSource
        Description: "SSH from remote client"
      - IpProtocol: tcp
        FromPort: 8443
        ToPort: 8443
        CidrIp: !Ref SshSource
        Description: "DCV WebSocket traffic"
      - IpProtocol: udp
        FromPort: 8443
        ToPort: 8443
        CidrIp: !Ref SshSource
        Description: "DCV QUIC UDP traffic"

  LSFMasterRole:
      Type: "AWS::IAM::Role"
      Properties:
        Description: AWS service permissions for LSF Resource Connector
        Path: "/"
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            -
              Effect: Allow
              Principal:
                Service:
                - "ec2.amazonaws.com"
              Action:
              - "sts:AssumeRole"
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy"
          - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
        Policies:
          - PolicyName: LSFResourceConnectorPerms
            PolicyDocument:
              Version: 2012-10-17
              Statement:
                - Effect: Allow
                  Action:
                    - ec2:AssociateIamInstanceProfile
                    - ec2:CancelSpotFleetRequests
                    - ec2:CreateFleet
                    - ec2:CreateLaunchTemplateVersion
                    - ec2:CreateTags
                    - ec2:DeleteFleets
                    - ec2:DeleteLaunchTemplateVersions
                    - ec2:DescribeFleetInstances
                    - ec2:DescribeFleetHistory
                    - ec2:DescribeFleets
                    - ec2:DescribeInstances
                    - ec2:DescribeInstanceStatus
                    - ec2:DescribeKeyPairs
                    - ec2:DescribeLaunchTemplateVersions
                    - ec2:DescribeSpotFleetInstances
                    - ec2:DescribeSpotFleetRequestHistory
                    - ec2:DescribeSpotFleetRequests
                    - ec2:DescribeSpotInstanceRequests
                    - ec2:GetLaunchTemplateData
                    - ec2:ModifyIdFormat
                    - ec2:ModifySpotFleetRequest
                    - ec2:ReplaceIamInstanceProfileAssociation
                    - ec2:RequestSpotFleet
                    - ec2:RunInstances
                    - ec2:TerminateInstances
                  Resource: '*'
                - Effect: Allow
                  Action:
                    - iam:PassRole
                    - iam:ListRoles
                    - iam:ListInstanceProfiles
                    - iam:CreateServiceLinkedRole
                  Resource:
                    - !GetAtt LSFSpotFleetRole.Arn
                    - !GetAtt LSFComputeNodeRole.Arn
                  Condition:
                      StringEquals:
                        iam:PassedToService:
                            "ec2.amazonaws.com"
                - Effect: Allow
                  Action:
                    - s3:GetObject
                  Resource: '*'

  LSFSpotFleetRole:
      Type: "AWS::IAM::Role"
      Properties:
        Description: Enables EC2 Spot Fleet to work on behalf of LSF Resource Connector
        Path: "/"
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            -
              Effect: Allow
              Principal:
                Service:
                - "spotfleet.amazonaws.com"
              Action:
              - "sts:AssumeRole"
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/service-role/AmazonEC2SpotFleetTaggingRole"

  LSFComputeNodeRole:
      Type: "AWS::IAM::Role"
      Properties:
        Description: AWS service permissions for LSF compute nodes
        Path: "/"
        AssumeRolePolicyDocument:
          Version: '2012-10-17'
          Statement:
            -
              Effect: Allow
              Principal:
                Service:
                - "ec2.amazonaws.com"
              Action:
              - "sts:AssumeRole"
        ManagedPolicyArns:
          - "arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy"
          - "arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"
        Policies:
          - PolicyName: DownloadS3Packages
            PolicyDocument:
              Version: 2012-10-17
              Statement:
                - Effect: Allow
                  Action:
                    - s3:GetObject
                  Resource: '*'

  LSFMasterInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: "/"
      Roles:
        - !Ref LSFMasterRole

  LSFComputeNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: "/"
      Roles:
        - !Ref LSFComputeNodeRole

  LSFMasterSG:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: "SG for LSF Master"
      VpcId: !Ref VpcId

  LSFComputeNodeSG:
    Type: "AWS::EC2::SecurityGroup"
    Properties:
      GroupDescription: "SG for LSF Compute Nodes"
      VpcId: !Ref VpcId

  LSFMasterSGRule01:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref LSFMasterSG
      Description: "SSH ingress"
      IpProtocol: tcp
      FromPort: 22
      ToPort: 22
      CidrIp: !Ref SshSource

  LSFMasterSGRule02:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref LSFMasterSG
      Description: "All traffic from LSF Compute Nodes"
      IpProtocol: "-1"
      SourceSecurityGroupId: !Ref LSFComputeNodeSG

  LSFMasterSGRule03:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref LSFMasterSG
      Description: "All traffic from Login Server"
      IpProtocol: "-1"
      SourceSecurityGroupId: !Ref LoginServerSG

  LSFComputeNodeSGRule01:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref LSFComputeNodeSG
      Description: "All traffic from LSF Master"
      IpProtocol: "-1"
      SourceSecurityGroupId: !Ref LSFMasterSG

  LSFComputeNodeSGRule02:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref LSFComputeNodeSG
      Description: "All traffic from other LSF exec hosts"
      IpProtocol: "-1"
      SourceSecurityGroupId: !Ref LSFComputeNodeSG

  LSFComputeNodeSGRule03:
    Type: "AWS::EC2::SecurityGroupIngress"
    Properties:
      GroupId: !Ref LSFComputeNodeSG
      Description: "SSH Ingress"
      IpProtocol: "tcp"
      FromPort: 22
      ToPort: 22
      CidrIp: !Ref SshSource

  FSxOntapFS:
    Type: "AWS::FSx::FileSystem"
    Properties:
      FileSystemType: "ONTAP"
      StorageType: SSD
      StorageCapacity: 1024
      SubnetIds:
        - !Ref ComputeNodeSubnet
      SecurityGroupIds:
        - !Ref FSxOntapSG
      OntapConfiguration:
        DeploymentType: "SINGLE_AZ_1"
        PreferredSubnetId: !Ref ComputeNodeSubnet
        ThroughputCapacity: 128
        DiskIopsConfiguration:
          Iops: 3072
          Mode: "USER_PROVISIONED"
      Tags:
        - Key: "Name"
          Value: "FSxN-FS"
  FSxOntapStorageVirtualMachine:
    Type: "AWS::FSx::StorageVirtualMachine"
    Properties:
        FileSystemId: !Ref FSxOntapFS
        Name: "svm1"
        RootVolumeSecurityStyle: "UNIX"
        Tags:
          - Key: "Name"
            Value: "FSxN-SVM"
  FSxOntapVolume:
    Type: "AWS::FSx::Volume"
    Properties:
      Name: "vol1"
      VolumeType: "ONTAP"
      OntapConfiguration:
        JunctionPath: "/vol1"
        SecurityStyle: "UNIX"
        SizeInMegabytes: 512000
        StorageEfficiencyEnabled: False
        StorageVirtualMachineId: !Ref FSxOntapStorageVirtualMachine
        TieringPolicy:
          CoolingPeriod: 31
          Name: "AUTO"
      Tags:
        - Key: "Name"
          Value: "FSxN-vol1"

  FSxOntapSG:
   Type: "AWS::EC2::SecurityGroup"
   Properties:
     GroupDescription: "SG for FSxN file systems"
     VpcId: !Ref VpcId
     SecurityGroupIngress:
     - IpProtocol: tcp
       FromPort: 22
       ToPort: 22
       SourceSecurityGroupId: !Ref LSFMasterSG
       Description: "SSH from LSF Mgmt Server"

  FSxOntapSGRule01:
   Type: AWS::EC2::SecurityGroupIngress
   Properties:
     GroupId: !Ref FSxOntapSG
     Description: "All traffic from LSF masters"
     IpProtocol: -1
     SourceSecurityGroupId: !Ref LSFMasterSG

  FSxOntapSGRule02:
   Type: AWS::EC2::SecurityGroupIngress
   Properties:
     GroupId: !Ref FSxOntapSG
     Description: "NFS from LSF compute nodes"
     IpProtocol: -1
     SourceSecurityGroupId: !Ref LSFComputeNodeSG

  FSxOntapSGRule03:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
     GroupId: !Ref FSxOntapSG
     Description: "NFS from LSF login servers"
     IpProtocol: -1
     SourceSecurityGroupId: !Ref LoginServerSG

  DCVCredentialsSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: !Sub '${AWS::StackName}/DCVCredentialsSecret'
      GenerateSecretString:
        SecretStringTemplate: '{"username": "simuser"}'
        GenerateStringKey: "password"
        PasswordLength: 16
        ExcludeCharacters: '"@/\'

  CloudWatchAgentConfiguration:
    Type: AWS::SSM::Parameter
    Properties:
      Description: SSM Parameter holding CloudWatchAgent configuration
      Name: !Sub ${LSFClusterName}-AmazonCloudWatch
      Type: String
      Value: |
        {
          "agent": {
            "metrics_collection_interval": 60,
            "logfile": "/opt/aws/amazon-cloudwatch-agent/logs/amazon-cloudwatch-agent.log",
            "debug": false
          },
          "logs": {
            "logs_collected": {
              "files": {
                "collect_list": [
                  {
                    "file_path": "/var/log/lsf/aws-provider.log*",
                    "log_group_name": "/var/log/lsf/rc/aws-provider.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/aws-provider.log*",
                    "log_group_name": "/var/log/lsf/rc/ebrokerd",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/Install.log*",
                    "log_group_name": "/var/log/lsf/Install.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/lim.log*",
                    "log_group_name": "/var/log/lsf/lim.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/mbatchd.log*",
                    "log_group_name": "/var/log/lsf/mbatchd.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/mbschd.log*",
                    "log_group_name": "/var/log/lsf/mbschd.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/mosquitto.log*",
                    "log_group_name": "/var/log/lsf/mosquitto.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/pim.log*",
                    "log_group_name": "/var/log/lsf/pim.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/res.log*",
                    "log_group_name": "/var/log/lsf/res.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/lsf/sbatchd.log*",
                    "log_group_name": "/var/log/lsf/sbatchd.log",
                    "log_stream_name": "{instance_id}"
                  },
                  {
                    "file_path": "/var/log/user-data.log*",
                    "log_group_name": "/var/log/lsf/user-data.log",
                    "log_stream_name": "{instance_id}"
                  }
                ]
              }
            }
          },
          "metrics": {
            "namespace": "CWAgent",
            "append_dimensions": {
              "InstanceId": "${aws:InstanceId}"
            },
            "metrics_collected": {
              "mem": {
                "measurement": ["mem_used_percent"],
                "metrics_collection_interval": 60
              }
            }
          }
        }

  AmazonCloudWatchSetConfig:
    Type: AWS::SSM::Association
    Properties:
      ApplyOnlyAtCronInterval: false
      AssociationName: AmazonCloudWatchSetConfig
      Name: AmazonCloudWatch-ManageAgent
      Parameters:
        action:
          - configure
        mode:
          - ec2
        optionalConfigurationLocation:
          - !Ref CloudWatchAgentConfiguration
        optionalConfigurationSource:
          - ssm
        optionalRestart:
          - "yes"
      ScheduleExpression: cron(0 */30 * * * ? *)
      Targets:
        - Key: tag:Name
          Values:
            - !Join [ '', [ 'LSF Mgmt Host - ',!Ref LSFClusterName ] ]

  LaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateName: !Sub ${AWS::StackName}-launch-template
      LaunchTemplateData:
        ImageId: !FindInMap [ RegionMap, !Ref "AWS::Region", !Ref ComputeAMI ]
        KeyName: !Ref AdminKeyPair
        IamInstanceProfile:
          Arn: !GetAtt LSFComputeNodeInstanceProfile.Arn
        SecurityGroupIds:
          - !Ref LSFComputeNodeSG

Outputs:
  LoginServerSsh:
    Description: Login server SSH command
    Value: !Sub 'ssh -i /path/to/${AdminKeyPair}.pem rocky@${LoginServerInstance.PublicIp}'
  LoginServerRemoteDesktop:
    Description: Connect to the cluster login/remote desktop server with this IP, using the native DCV client.
    Value: !Sub '${LoginServerInstance.PublicIp}:8443'
  DCVUserName:
    Description: Login name for DCV session
    Value: !Ref 'UserName'
  SSHTunnelCommand:
    Description: >
      Command for setting up an SSH tunnel from your local host to the remote desktop. Use "localhost:18443" as
      the connection address in the DCV client. This is helpful if outbound port 8443 is blocked by a proxy.
    Value: !Sub 'ssh -i /path/to/${AdminKeyPair}.pem -L 18443:localhost:8443 -l rocky ${LoginServerInstance.PublicIp}'

