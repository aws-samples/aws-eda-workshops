AWSTemplateFormatVersion: '2010-09-09'
Conditions:
  Has_Bucket: !Not
    - !Equals
      - !Ref 'S3BucketName'
      - NO_VALUE
  Has_Public_Ip: !Equals
    - !Ref 'UsePublicIp'
    - 'True'
  Has_Static_Private_IP: !Not
    - !Equals
      - !Ref 'StaticPrivateIpAddress'
      - NO_VALUE
  create_elastic_ip: !Equals
    - !Ref 'CreateElasticIP'
    - 'True'
  no_placement_group: !Equals
    - !Ref 'ExistingPlacementGroup'
    - NO_VALUE
  not_existing_sg: !Equals
    - !Ref 'ExistingSecurityGroup'
    - NO_VALUE
Description: Currently supporting RHEL/CentOS 7.6. Setup IAM role and security groups,
  launch instance, use local NVMe volumes, use ZFS or software RIAD (mdadm) for FS,
  and setup NFS server
Mappings:
  AWSRegionAMI:
    ap-northeast-1:
      centos7: ami-045f38c93733dd48d
      rhel7: ami-08419d23bf91152e4
    ap-northeast-2:
      centos7: ami-06cf2a72dadf92410
      rhel7: ami-07be38aae5985872f
    ap-northeast-3:
      centos7: ami-054dd155c89b8d778
    ap-south-1:
      centos7: ami-02e60be79e78fef21
      rhel7: ami-09a4d6a78af9e9a73
    ap-southeast-1:
      centos7: ami-0b4dd9d65556cac22
      rhel7: ami-01b02e6dd3efebd61
    ap-southeast-2:
      centos7: ami-08bd00d7713a39e7d
      rhel7: ami-08d099ec55a5c5a16
    ca-central-1:
      centos7: ami-033e6106180a626d0
      rhel7: ami-0c896f6be8b26325e
    eu-central-1:
      centos7: ami-04cf43aca3e6f3de3
      rhel7: ami-00e37cffd3bb3ac8d
    eu-north-1:
      centos7: ami-5ee66f20
      rhel7: ami-95b53beb
    eu-west-1:
      centos7: ami-0ff760d16d9497662
      rhel7: ami-0e12cbde3e77cbb98
    eu-west-2:
      centos7: ami-0eab3a90fc693af19
      rhel7: ami-0b1eb35fb81061601
    eu-west-3:
      centos7: ami-0e1ab783dc9489f34
      rhel7: ami-0da6335c8dff5d55a
    sa-east-1:
      centos7: ami-0b8d86d4bf91850af
      rhel7: ami-071ceb2e9e4b0ae06
    us-east-1:
      centos7: ami-02eac2c0129f6376b
      rhel7: ami-011b3ccf1bd6db744
    us-east-2:
      centos7: ami-0f2b4fc905b0bd1f1
      rhel7: ami-0b500ef59d8335eee
    us-west-1:
      centos7: ami-074e2d6769f445be5
      rhel7: ami-0ec1ad91f200c15a8
    us-west-2:
      centos7: ami-01ed306a12b7d1c96
      rhel7: ami-036affea69a1101c9
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Instance Configuration
        Parameters:
          - NFSInstanceType
          - AdminKeyPair
          - OperatingSystem
          - VPCId
          - Subnet
          - UsePublicIp
          - CreateElasticIP
          - StaticPrivateIpAddress
          - SshSource
          - ExistingSecurityGroup
          - ExistingPlacementGroup
          - S3BucketName
      - Label:
          default: NFS Options - Required
        Parameters:
          - NFSCidr
          - NFSOpts
      - Label:
          default: Volume and RAID Configuration
        Parameters:
          - VolumeType
          - RAIDLevel
          - ZfsOrMdadm
      - Label:
          default: ZFS Pool and FS Options - Required if using ZFS
        Parameters:
          - ZfsPool
          - ZfsMountPoint
          - UseL2arc
          - UseZil
    ParameterLabels:
      - CreateElasticIP:
          default: 'Create and use an EIP '
        AdminKeyPair:
          default: EC2 Key Name
        ExistingPlacementGroup:
          default: 'OPTIONAL:  Existing Placement Group'
        ExistingSecurityGroup:
          default: 'OPTIONAL:  Existing Security Group'
        NFSInstanceType:
          default: Instance Type
        OperatingSystem:
          default: Operating System of AMI
        S3BucketName:
          default: Optional S3 Bucket Name
        SshSource:
          default: SSH Access CIDR Block
        StaticPrivateIpAddress:
          default: Static Private IP
        Subnet:
          default: Subnet ID
        UsePublicIp:
          default: 'Assign a Public IP '
        VPCId:
          default: VPC ID
      - NFSCidr:
          default: NFS CIDR block for mounts
        NFSOpts:
          default: NFS options
      - RAIDLevel:
          default: RAID Level
        VolumeType:
          default: Storage volume type
      - UseL2arc:
          default: Use l2arc for ZFS
        UseZil:
          default: Use zil for ZFS
        ZfsMountPoint:
          default: Mount Point
        ZfsOrMdadm:
          default: Use ZFS or Software Raid (mdadm)
        ZfsPool:
          default: ZFS pool name
        EDAInstallPath:
          default: "Path to EDA tools and project data"
    
Parameters:
  CreateElasticIP:
    AllowedValues:
      - 'True'
      - 'False'
    ConstraintDescription: True/False
    Default: 'False'
    Description: Create an Elasic IP address that will be assinged to the instance
    Type: String
  AdminKeyPair:
    ConstraintDescription: 'REQUIRED: Must be a valid EC2 key pair'
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance.
    Type: AWS::EC2::KeyPair::KeyName
  ExistingPlacementGroup:
    Default: NO_VALUE
    Description: 'OPTIONAL:  Existing placement group'
    Type: String
  ExistingSecurityGroup:
    Default: NO_VALUE
    Description: 'OPTIONAL: Choose an existing Security Group ID, e.g. sg-abcd1234'
    Type: String
  NFSCidr:
    AllowedPattern: (\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})
    ConstraintDescription: Must be a valid CIDR x.x.x.x/x
    Default: 10.0.0.0/16
    Description: CIDR for NFS Security Group and NFS clients, to allow all access
      use 0.0.0.0/0
    Type: String
  NFSInstanceType:
    AllowedValues:
      - i3.16xlarge
      - i3.metal
      - p3dn.24xlarge
    ConstraintDescription: Must an EC2 instance type from the list
    Default: i3.16xlarge
    Description: NFS instance type
    Type: String
  NFSOpts:
    Default: (rw,async,no_root_squash,wdelay,no_subtree_check,no_acl)
    Description: NFS export options
    Type: String
  OperatingSystem:
    AllowedValues:
      - centos7
      - rhel7
    ConstraintDescription: 'Must be: centos7, rhel7'
    Default: centos7
    Description: Operating System
    Type: String
  RAIDLevel:
    AllowedValues:
      - '0'
    ConstraintDescription: Must be 0 for now
    Default: '0'
    Description: RAID Level
    Type: String
  S3BucketName:
    Default: NO_VALUE
    Description: S3 bucket to allow this instance read access.
    Type: String
  SshSource:
    AllowedPattern: (\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})
    ConstraintDescription: Must be a valid CIDR x.x.x.x/x
    Default: 111.222.333.444/32
    Description: CIDR Block for SSH access
    Type: String
  StaticPrivateIpAddress:
    Default: NO_VALUE
    Description: Assign static Private IP address
    Type: String
  Subnet:
    Description: Subnet IDs
    Type: String
    Default: NO_VALUE
  UseL2arc:
    AllowedValues:
      - 'True'
      - 'False'
    Default: 'True'
    Description: Should the l2arc option be used for the ZFS file system
    Type: String
  UsePublicIp:
    AllowedValues:
      - 'True'
      - 'False'
    ConstraintDescription: True/False
    Default: 'False'
    Description: Should a public IP address be given to the instance, this is overridden
      by CreateElasticIP=True
    Type: String
  UseZil:
    AllowedValues:
      - 'True'
      - 'False'
    Default: 'True'
    Description: Should the zil option be used for the ZFS file system
    Type: String
  VPCId:
    Description: VPC Id for this instance
    Type: String
    Default: NO_VALUE
  VolumeType:
    AllowedValues:
      - InstanceStore
    ConstraintDescription: Volume type has to EBS or InstanceStore, which is auto-selected
    Default: InstanceStore
    Description: 'Using auto-selected VolumeType: InstanceStore'
    Type: String
  ZfsMountPoint:
    Default: zfs1
    Description: ZFS mount point, absolute path will be /pool_name/mount_point (e.g.
      /v01/zfs1)
    Type: String
  ZfsOrMdadm:
    AllowedValues:
      - ZFS
    ConstraintDescription: Must be ZFS
    Default: ZFS
    Description: 'ZFS or mdadm auto-selected by template, using: ZFS'
    Type: String
  ZfsPool:
    Default: v01
    Description: ZFS pool name
    Type: String
  LSFClusterName:
    Description: "The name of the computing environment.  This will also be the name of the LSF cluster."
    Type: "String"
    Default: cde-1
  EDAInstallPath:
    Description: "Path for EDA tools and design data"
    Type: String
    Default: "/proj"

Resources:
  BucketPolicy:
    Condition: Has_Bucket
    Properties:
      PolicyDocument:
        Statement:
          - Action:
              - s3:GetObject
            Effect: Allow
            Resource: !Sub 'arn:aws:s3:::${S3BucketName}/*'
          - Action:
              - s3:ListBucket
            Effect: Allow
            Resource: !Sub 'arn:aws:s3:::${S3BucketName}'
        Version: '2012-10-17'
      PolicyName: BucketPolicy
      Roles:
        - !Ref 'RootRole'
    Type: AWS::IAM::Policy
  EIPAddress:
    Condition: create_elastic_ip
    Properties:
      Domain: vpc
      InstanceId: !Ref 'NFSInstance'
    Type: AWS::EC2::EIP
  NFSInstance:
    Type: AWS::EC2::Instance
    Properties:
      DisableApiTermination: false
      IamInstanceProfile: !Ref 'RootInstanceProfile'
      ImageId: !FindInMap
        - AWSRegionAMI
        - !Ref 'AWS::Region'
        - !Ref 'OperatingSystem'
      InstanceType: !Ref 'NFSInstanceType'
      KeyName: !Ref 'AdminKeyPair'
      NetworkInterfaces:
        - AssociatePublicIpAddress: !Ref 'UsePublicIp'
          DeleteOnTermination: true
          DeviceIndex: '0'
          GroupSet: !If
            - not_existing_sg
            - - Fn::ImportValue: !Join [ '-', [ !Ref LSFClusterName,"NFSServerSG" ] ]
            - - Fn::ImportValue: !Join [ '-', [ !Ref LSFClusterName,"NFSServerSG" ] ]
              - !Ref 'ExistingSecurityGroup'
          PrivateIpAddress: !If
            - Has_Static_Private_IP
            - !Ref 'StaticPrivateIpAddress'
            - !Ref 'AWS::NoValue'
          SubnetId: 
            Fn::ImportValue: !Join [ '-', [ !Ref LSFClusterName,"PrivateSubnet" ] ]
      PlacementGroupName: !If
        - no_placement_group
        - !Ref 'AWS::NoValue'
        - !Ref 'ExistingPlacementGroup'
      Tags:
        - 
          Key: "Name"
          Value: !Join [ '-', [ 'NFS Server',!Ref LSFClusterName ] ]
        - 
          Key: "Cluster"
          Value: !Ref LSFClusterName

      UserData: !Base64
        Fn::Sub: 
          - |
            #!/usr/bin/env bash

            set -x
            exec > >(tee /var/log/user-data.log|logger -t user-data ) 2>&1

            echo "*** BEGIN NFS SERVER BOOTSTRAP ***"

            ##exit 0

            nfs_instance_type="${NFSInstanceType}"
            nfs_cidr_block="${VpcCIDR}"
            nfs_opts="${NFSOpts}"
            my_wait_handle="${NFSInstanceWaitHandle}"
            volume_type="${VolumeType}"
            hypervisor_type="nitro"
            zfs_or_mdadm="${ZfsOrMdadm}"

            zfs_pool_name="${ZfsPool}"
            zfs_mount_point="${ZfsMountPoint}"
            use_l2arc="${UseL2arc}"
            use_zil="${UseZil}"
            #@IgnoreInspection BashAddShebang

            #
            # Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
            #
            # Licensed under the Apache License, Version 2.0 (the "License"). You may not use this file
            # except in compliance with the License. A copy of the License is located at
            #
            #     http://aws.amazon.com/apache2.0/
            #
            # or in the "license" file accompanying this file. This file is distributed on an "AS IS"
            # BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
            # License for the specific language governing permissions and limitations under the License.
            #

            function inst_pkgs {
              echo "Installing packages and updates"
              sudo yum install nfs-utils rpcbind -y
              sudo yum install vim -y
              sudo yum install nvme-cli -y
              sudo yum install mdadm -y
              sudo yum update -y
              echo "Updates complete"
            }

            function inst_ssm {
              echo "Installing and starting AWS Systems Manager (SSM) agent"
              sudo yum install -q -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm
              systemctl enable amazon-ssm-agent
              systemctl start amazon-ssm-agent
            }

            function ck_devs_count_build_list {

              if [[ "$volume_type" == "EBS" ]]; then
                echo "Checking the total number of EBS volumes, currently ${!devs_count_ready} devices ready."
                devs_count_ready=0
                let dev_count=$(sudo nvme list | grep "${!nvme_grep_str}" | grep -v nvme0n1 | wc -l)
                if [[ $dev_count -eq ${!total_ebs_vols} ]]; then
                  if [[ ! ${!dev_list} ]]; then
                    for d in $(sudo nvme list | grep "${!nvme_grep_str}" | grep -v nvme0n1 | awk {'print $1'} | cut -f3 -d"/")
                      do echo -n "$d "
                      dev_list="${!dev_list} ${!d}"
                    done
                  fi
                  devs_count_ready=1
                else
                  devs_count_ready=0
                fi
              elif [[ "$volume_type" == "InstanceStore" ]]; then
                echo "Checking the total number of Instance Store NVMe volumes, currently ${!devs_count_ready} devices ready."
                devs_count_ready=0
                let dev_count=$(sudo nvme list | grep "${!nvme_grep_str}" | wc -l)
                if [[ $dev_count -eq ${!total_i_store_vols} ]]; then
                  if [[ ! ${!dev_list} ]]; then
                    for d in $(sudo nvme list | grep "${!nvme_grep_str}" | awk {'print $1'} | cut -f3 -d"/")
                      do echo -n "$d "
                      dev_list="${!dev_list} ${!d}"
                    done
                  fi
                  devs_count_ready=1
                else
                  devs_count_ready=0
                fi
              fi

            }

            timeout_count=0
            function ck_devs {
              devs_ready=0

              if [[ "$volume_type" == "EBS" ]]; then
                nvme_grep_str="Amazon Elastic Block Store"
                total_ebs_vols=8
                total_vols=${!total_ebs_vols}
              elif [[ "$volume_type" == "InstanceStore" ]]; then
                nvme_grep_str="Amazon EC2 NVMe Instance Storage"
                total_i_store_vols=${!instStore_devs["${!nfs_instance_type}"]}
                total_vols=${!total_i_store_vols}
              fi

              while [[ ! $(which nvme) ]]; do
                sleep 10
              done

              while [[ ! ${!devs_count_ready} ]]; do
                ck_devs_count_build_list
                sleep 10
              done

              echo "Using device list ${!dev_list}"

              while [[ ! ${!devs_ready} ]]; do
                for l in ${!dev_list}; do
                  if [[ ! -b /dev/${!l} ]]; then
                    devs_ready=0
                    ((timeout_count = $timeout_count + 1))
                    if [[ $timeout_count -gt 30 ]]; then
                      echo "All storage volumes are ready, exiting..."
                      exit
                    else
                      sleep 10
                    fi
                  else
                    devs_ready=1
                    ck_devs
                  fi
                done
              done
              echo "Devices ready."
            }

            function mk_raid {
              raid_level="0"
              full_path_dev_list=""
              for d in ${!dev_list}; do
                temp_d="/dev/${!d}"
                full_path_dev_list="${!full_path_dev_list} ${!temp_d}"
              done
              yes | sudo mdadm --create --verbose /dev/md0 --level=${!raid_level} --name=raid-vol1 --raid-devices=${!total_vols} ${!full_path_dev_list}
            }

            function mk_ext4_fs {
              mdadm_fs_dev="/dev/md0"
              mdadm_fs_name=${!mdadm_raid_fs_name}
              mdadm_fs_label=${!mdadm_raid_fs_name}
              sudo mkfs.ext4 -L ${!mdadm_fs_label} ${!mdadm_fs_dev} -E nodiscard
              sudo mkdir /${!mdadm_fs_name}
              sudo mount LABEL=${!mdadm_fs_label} /${!mdadm_fs_name}
              sudo su -c "echo 'LABEL=${!mdadm_fs_label}       /${!mdadm_fs_name}   ext4    defaults,nofail        0       2' >> /etc/fstab"
            }

            function fix_zfs_repo {
              echo "Fixing ZFS repo..."
              sudo cat /etc/yum.repos.d/zfs.repo  | while read l
              do
                if [[ "$l" == "[zfs]" ]]; then
                  let on_zfs=1
                elif [[ "$l" == "[zfs-kmod]" ]]; then
                  let on_zfs_kmod=1
                fi
                if [[ "$on_zfs" -eq 1 ]] && [[ "$l" == "enabled=1" ]]; then
                  l="enabled=0"
                  let on_zfs=0
                elif [[ "$on_zfs_kmod" -eq 1 ]] &&  [[ "$l" == "enabled=0" ]]; then
                  l="enabled=1"
                  let on_zfs_kmod=0
                fi
                echo $l
              done > /tmp/new_zfs.repo
              sudo cp /etc/yum.repos.d/zfs.repo /etc/yum.repos.d/zfs.repo.dist
              sudo mv /tmp/new_zfs.repo /etc/yum.repos.d/zfs.repo
              echo "Done fixing ZFS repo"

            }

            function zfs_install {
              echo -n "Fixing, removing, and re-installing ZFS..."
              known_zfs_key="C93AFFFD9F3F7B03C310CEB6A9D5A1C0F14AB620"
              sudo yum -y remove zfs zfs-kmod spl spl-kmod libzfs2 libnvpair1 libuutil1 libzpool2 zfs-release
              sudo yum -y install http://download.zfsonlinux.org/epel/zfs-release.el7_6.noarch.rpm
              actual_zfs_key=$(gpg --quiet --with-fingerprint /etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux | grep "Key fingerprint" | cut -d"=" -f2 | tr -d ' ')
              echo "Checking keys..."
              if [[ "$known_zfs_key" != "$actual_zfs_key" ]]; then
                echo "ERROR: ZFS installation keys not valid!!!"
                echo "Exiting..."
                exit
              fi
              fix_zfs_repo
              sudo yum -y autoremove
              sudo yum -y clean metadata
              sudo yum -y install zfs
              echo "Done installing ZFS"
            }

            function zfs_create {
              ##((zfs_nvme_first_dev = $local_nvme_last_dev + 1))
              ##((zfs_nvme_last_dev = $zfs_nvme_first_dev + 7))

              echo "Using these devices for ZFS:"
              sudo nvme list | grep "Amazon Elastic Block Store" | grep -v nvme0n1

              sudo /sbin/modprobe zfs
              modinfo zfs
              sudo zpool create -O compression=lz4 -O atime=off -O sync=disabled -f ${!zfs_pool_name} -o ashift=12 ${!dev_list}
              sudo zpool status -v
              sudo zfs create ${!zfs_pool_name}/${!zfs_mount_point}
            }

            function zfs_startup {
              sudo systemctl enable zfs-import-cache
              sudo systemctl enable zfs-mount.service
              sudo systemctl enable zfs.target
            }

            function nfs_server_settings {
              sudo su -c 'echo -e "STATD_PORT=\"32765\"\nSTATD_OUTGOING_PORT=\"32766\"\nSTATDARG=\"-p 32765 -o 32766\"\nMOUNTD_PORT=\"32767\"\nRPCMOUNTDOPTS=\"-p 32767\"
            LOCKD_UDPPORT=\"32768\"\nLOCKD_TCPPORT=\"32768\"\nRQUOTAD_PORT=\"32769\"\nRQUOTAD=\"no\"\nRPCNFSDCOUNT=\"128\""' > /etc/sysconfig/nfs
            }

            function nfs_config {
              nfs_server_settings

              if [[ "${!zfs_or_mdadm}" == "ZFS" ]]; then
                sudo su -c 'echo "'"/${!zfs_pool_name}/${!zfs_mount_point} ${!nfs_cidr_block}${!nfs_opts}"'" > /etc/exports'
              elif [[ "${!zfs_or_mdadm}" == "mdadm" ]]; then
                sudo su -c 'echo "'"/${!mdadm_raid_fs_name} ${!nfs_cidr_block}${!nfs_opts}"'" > /etc/exports'
              fi
              sudo systemctl enable rpcbind
              sudo systemctl enable nfs-server
              sudo systemctl start rpcbind
              sudo systemctl start nfs-server
              sudo systemctl start rpc-statd
              showmount -e localhost
            }

            function ck_status {

              if [[ "${!zfs_or_mdadm}" == "ZFS" ]]; then
                zfs_status=$(sudo zpool status | grep state | awk {'print $2'})
                sudo mount | grep ${!zfs_pool_name}
                let zfs_mount_rc=$?
                sudo showmount -e localhost | grep -v Export | grep ${!zfs_mount_point}
                let nfs_status_rc=$?
                if [[ "${!zfs_status}" == "ONLINE" ]] && [[ "${!nfs_status_rc}" -eq 0 ]] && [[ "${!zfs_mount_rc}" -eq 0 ]]; then
                  echo "ZFS and NFS installed and configured"
                  curl -X PUT -H 'Content-Type:' --data-binary '{ "Status" : "SUCCESS",  "Reason" : "ZFS and NFS installed and configured",  "UniqueId" : "ZFS001",  "Data" : "ZFS and NFS installed and configured."}'    "${!my_wait_handle}"
                fi
              elif [[ "${!zfs_or_mdadm}" == "mdadm" ]]; then
                mdadm_status=$(sudo mdadm --detail /dev/md0 | grep "State :" | awk {'print $NF'})
                sudo mount | grep ${!mdadm_fs_name}
                let mdadm_mount_rc=$?
                sudo showmount -e localhost | grep -v Export | grep ${!mdadm_fs_name}
                let nfs_status_rc=$?
                if [[ "${!mdadm_status}" == "clean" ]] && [[ "${!nfs_status_rc}" -eq 0 ]] && [[ "${!mdadm_mount_rc}" -eq 0 ]]; then
                  echo "mdadm raid and NFS installed and configured"
                  curl -X PUT -H 'Content-Type:' --data-binary '{ "Status" : "SUCCESS",  "Reason" : "mdadm raid and NFS installed and configured",  "UniqueId" : "ZFS001",  "Data" : "mdadm raid and NFS installed and configured."}'    "${!my_wait_handle}"
                fi
              fi
            }

            declare -A instStore_devs

            instStore_devs["i3.16xlarge"]=8
            instStore_devs["i3.metal"]=8
            instStore_devs["p3dn.24xlarge"]=2

            inst_pkgs
            inst_ssm
            ck_devs

            if [[ "${!zfs_or_mdadm}" == "ZFS" ]]; then
              zfs_install
              zfs_create
              zfs_startup
            elif [[ "${!zfs_or_mdadm}" == "mdadm" ]]; then
              mk_raid
              mk_ext4_fs
            fi

            nfs_config
            ck_status

            echo "*** END NFS SERVER BOOTSTRAP ***"

          - VpcCIDR:
              Fn::ImportValue: !Join [ '-', [ !Ref LSFClusterName,"VpcCIDR" ] ]

  NFSInstanceWaitCondition:
    DependsOn: NFSInstance
    Properties:
      Handle: !Ref 'NFSInstanceWaitHandle'
      Timeout: '3600'
    Type: AWS::CloudFormation::WaitCondition
  NFSInstanceWaitHandle:
    Type: AWS::CloudFormation::WaitConditionHandle
  
  RootInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: "/"
      Roles:
        - !Ref RootRole
  RootRole:
    Type: "AWS::IAM::Role"
    Properties:
      Path: "/"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - 
            Effect: Allow
            Principal:
              Service:
              - "ec2.amazonaws.com"
            Action:
            - "sts:AssumeRole"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM"

Outputs:
  ElasticIPAddress:
    Condition: create_elastic_ip
    Description: Elastic IP address for the instance
    Value: !GetAtt 'NFSInstance.PublicIp'
  ExampleClientMountCommands:
    Description: Example commands to mount NFS on the clients
    Value: !Sub 'sudo mkdir /mnt/nfs1; sudo mount ${NFSInstance.PrivateIp}:/${ZfsPool}/${ZfsMountPoint}
      /mnt/nfs1'
  InstanceID:
    Description: Instance ID
    Value: !Ref 'NFSInstance'
  InstancePrivateIP:
    Value: !GetAtt 'NFSInstance.PrivateIp'
  InstancePublicIP:
    Condition: Has_Public_Ip
    Value: !GetAtt 'NFSInstance.PublicIp'
  S3BucketName:
    Condition: Has_Bucket
    Value: !Ref 'S3BucketName'
  StaticPrivateIpAddress:
    Condition: Has_Static_Private_IP
    Value: !Ref 'StaticPrivateIpAddress'
  NFSServerExport:
    Description: NFS server IP and export point
    Value: !Join [ '', [ !GetAtt NFSInstance.PrivateIp, ":/", !Ref ZfsPool, "/", !Ref ZfsMountPoint ] ]
    Export:
      Name: !Join [ '-', [ !Ref LSFClusterName, "NFSServerExport" ] ]
